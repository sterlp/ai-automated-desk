spring:
  ai:
    chat:
      observations:
        log-completion: true
    ollama:
      base-url: http://192.168.178.87:11434 #  http://localhost:11434 # 
      chat:
        model: gemma3:12b # gemma3:4b qwen3 gemma3 llama3.1 granite3.3:8b gemma3:4b # gpt-oss:20b
      init:
        pull-model-strategy: always
        timeout: 300s
        max-retries: 1

ai-desk:
  docker: /usr/local/bin/docker

logging:
  level:
    org.sterl.ai.desk: debug